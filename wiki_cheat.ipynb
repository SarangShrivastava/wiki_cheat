{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cebeb61-d2b0-443a-be26-c13bac24888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import ast\n",
    "\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from sentence_transformers import CrossEncoder\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from helpers import chat\n",
    "\n",
    "root_path = '/home/ec2-user/sarang/wiki_cheat'\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(root_path))\n",
    "os.chdir(root_path)\n",
    "\n",
    "### Load the environment file\n",
    "env_file_path = find_dotenv()\n",
    "logging.info(f'env_file_path: {env_file_path}')\n",
    "load_dotenv(env_file_path)\n",
    "\n",
    "### API keys and tokens needed for interaction with external APIS\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'), pool_threads=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77237f-8972-45d7-a3d2-a5bf0c06b793",
   "metadata": {},
   "source": [
    "## Model and index Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a1362bb-542d-49e6-84bd-ed40f9a2b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_path = 'train_embedder/models/sentence-transformers-all-mpnet-base-v2-2024-01-27_20-14-10'\n",
    "reranker_model_path = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "reader_model = \"gpt-4-0125-preview\"\n",
    "index_name = \"wiki-all-mpnet-base-v2-trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd861482-fcbb-41b3-bd9c-9a923785b8c0",
   "metadata": {},
   "source": [
    "## Load relevant Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3c27938-fedb-459e-b146-383b79398726",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = SentenceTransformer(encoder_model_path, device='cuda')\n",
    "reranker_model = CrossEncoder(reranker_model_path, max_length=512, device='cuda')\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca0869-08d2-4465-ac9d-74441f40c279",
   "metadata": {},
   "source": [
    "## Helper methods for retrieving, reranking and reading of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19ec73df-8659-47f0-905b-0b72303aab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_results(query):\n",
    "    query_emb = encoder_model.encode(query, show_progress_bar=True, batch_size=512).tolist()\n",
    "    result = index.query(\n",
    "        vector=query_emb,\n",
    "        top_k=100,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return result['matches']\n",
    "\n",
    "def rerank_results(query, results):\n",
    "    reranked_results = []\n",
    "    predictions = [(query, res['metadata']['text']) for res in results]\n",
    "    scores = reranker_model.predict(predictions).tolist()\n",
    "    results_with_scores = [ {'res':res, 'score':scores[idx]} for idx, res in enumerate(results)]\n",
    "    for result in sorted(results_with_scores, key=lambda x: x['score'], reverse=True):\n",
    "        result['res']['rerank_score'] = result['score']\n",
    "        reranked_results.append(result['res'])\n",
    "    return reranked_results\n",
    "\n",
    "def get_reader_prompt():\n",
    "    \"\"\"\n",
    "    This function returns a multiline string that serves as a prompt for reading the reranked data\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"You are working as a Question Answering assistant. You will be given a question along with 10 passages. \n",
    "    You need to find the id of the passage that contains the answer to the question asked, \n",
    "    answer the question and provide a step by step reasoning for your answer.\n",
    "    --- INPUT 1: Input Question. This input is delimited by triple @.\n",
    "    @@@{input_question}@@@\n",
    "    --- INPUT 2: Set of passages. This input is delimited by triple @.\n",
    "    @@@{input_passages}@@@\n",
    "    --- TASK 1: You need to find the id of the passage that contains the answer to the question asked, \n",
    "    answer the question and provide a step by step reasoning for your answer.\n",
    "    --- CONSTRAINT 1: You should return a dictionary. That dictionary should have 3 keys. \n",
    "    First key is the 'id' which is the id of the passage that contains the answer, second key is 'answer' which is the answer to the question, \n",
    "    and Thrid key is the 'reason' which represents a step by step \n",
    "    reasoning for your answer. And \n",
    "    --- CONSTRAINT 2: If the answer is not present in any of the input passages you should return a dictionary with id as -1, answer as None and reason as Not present.\n",
    "    --- CONSTRAINT 3: You should not add any extra text before/after the json object that you return. Just return a list of dictionaries without any text before or after.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "    \n",
    "def read_results(query, reranked_results, read_top_k=10):\n",
    "    relevant_passages = [ {'id': idx, 'text': res['metadata']['title'] +\": \" + res['metadata']['text'] } \n",
    "                         for idx, res in enumerate(reranked_results[:read_top_k]) ]\n",
    "    prompt=  get_reader_prompt()\n",
    "    prompt = prompt.format(**{\"input_question\":query , \"input_passages\":relevant_passages})\n",
    "    try:\n",
    "        completion = chat(prompt, model=reader_model, response_format=\"json_object\")\n",
    "        answer = ast.literal_eval(completion.choices[0].message.content)\n",
    "        reader_answer = reranked_results[answer['id']], answer['answer']\n",
    "    except Exception as e:\n",
    "        reader_answer = reranked_results[0], \"\"\n",
    "    return reader_answer\n",
    "\n",
    "def run_pipeline(query):\n",
    "    results = retrieve_results(query)\n",
    "    reranked_results = rerank_results(query, results)\n",
    "    result, answer = read_results(query,reranked_results )\n",
    "    print(f\"Question: {query}\")\n",
    "    print(\"----------------\")\n",
    "    if answer:\n",
    "        print(f\"Answer: {answer}\")\n",
    "    print(f\"Wikipedia page: {result['metadata']['url']}\")\n",
    "    print(f\"Evidence paragraph: {result['metadata']['text']}\")\n",
    "    print(\"################\")\n",
    "    return { \"question\": query, \"answer\":answer, \"wikipedia_page\":result['metadata']['url'], \"paragraph\":result['metadata']['text']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51503415-0c4a-41f0-bc35-06c09bd556df",
   "metadata": {},
   "source": [
    "## Perform Dry run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d54d96a-e468-481c-8b05-56391c414c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d9956265a049ed96ef3d1dd1850453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How did anne frank die?\n",
      "----------------\n",
      "Answer: Anne and her older sister, Margot, died at Bergen-Belsen concentration camp from typhus.\n",
      "Wikipedia page: https://simple.wikipedia.org/wiki?curid=6312\n",
      "Evidence paragraph: However, that was not to be. Anne's father, Otto Frank, lived through the war and came back to Amsterdam. He hoped that his family had survived too - but they had not. Of all the family, only he survived. His wife was killed at Auschwitz. Anne and her older sister, Margot, died at Bergen-Belsen concentration camp from typhus, a disease - only a month before the camp was freed by the Allied forces. When he got out, he found Anne's diary and published it.\n",
      "################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a612f241b0a24392b4696f8c9993fa24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How are glaciers formed?\n",
      "----------------\n",
      "Answer: Glaciers are formed because the snow in an area does not all melt in summer. Each winter, more snow is added, and the weight of all the snow creates pressure. This pressure turns the lower parts of the snow into ice. After many years, the glacier starts growing large and moves due to gravity.\n",
      "Wikipedia page: https://simple.wikipedia.org/wiki?curid=34576\n",
      "Evidence paragraph: A glacier is a large body of ice and snow. It forms because the snow in an area does not all melt in summer. Each winter, more snow is added. The weight of all the snow creates pressure. This pressure turns the lower parts of the snow into ice. After this happens for many years, the glacier will start growing large. It becomes so heavy that gravity causes the ice to move. It flows downwards like water but very slowly. A glacier only moves about per year. New snowfalls replace the parts that flow away.\n",
      "################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db0a0484bca4153a38c50b3acb216ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How are glacier caves formed?\n",
      "----------------\n",
      "Answer: Glacier caves are formed by ice and glaciers.\n",
      "Wikipedia page: https://simple.wikipedia.org/wiki?curid=214942\n",
      "Evidence paragraph: A cave is a natural underground hollow space. They can have narrow passageways (corridors) and chambers (caverns). They are usually formed when underground acidic (sour) water wears away softer stones, such as limestone. Only the hard rock, such as granite, is left. Caves can also be formed during natural catastrophes, such as earthquakes, or by ice and glaciers.\n",
      "################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fb95f1ded94fd6bb4c0b1203c6bc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is a desktop computer and where is it typically placed?\n",
      "----------------\n",
      "Answer: A desktop computer is a small machine that has a screen (which is not part of the computer) and is typically placed on top of a desk.\n",
      "Wikipedia page: https://simple.wikipedia.org/wiki?curid=112\n",
      "Evidence paragraph: A \"desktop computer\" is a small machine that has a screen (which is not part of the computer). Most people keep them on top of a desk, which is why they are called \"desktop computers.\" \"Laptop computers\" are computers small enough to fit on your lap. This makes them easy to carry around. Both laptops and desktops are called personal computers, because one person at a time uses them for things like playing music, surfing the web, or playing video games.\n",
      "################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef97e60cad5413ea080ae061457e8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When did the Western Allies invade mainland Italy during World War II?\n",
      "----------------\n",
      "Answer: 3 September 1943\n",
      "Wikipedia page: https://simple.wikipedia.org/wiki?curid=429305\n",
      "Evidence paragraph: The Allied invasion of Italy was the invasion of mainland Italy by the Allies during World War II. The Allies landed on the mainland on 3 September 1943. The invasion followed the successful invasion of Sicily during the Italian Campaign.\n",
      "################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9f1c59fa1c4c71ba62088adbbc28ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What elements make up the Earth's core (approximately) ?\n",
      "----------------\n",
      "Answer: Iron (88.8%), nickel (5.8%), sulfur (4.5%), and less than 1% other things\n",
      "Wikipedia page: https://simple.wikipedia.org/wiki?curid=219\n",
      "Evidence paragraph: The structure of Earth changes from the inside to the outside. The center of earth (Earth's core) is mostly iron (88.8%), nickel (5.8%), sulfur (4.5%), and less than 1% other things. The Earth's crust is largely oxygen (47%). Oxygen is normally a gas but it can join with other chemicals to make compounds like water and rocks. 99.22% of rocks have oxygen in them. The most common oxygen-having rocks are silica (made with silicon), alumina (made with aluminium), rust (made with iron), lime (made with calcium), magnesia (made with magnesium), potash (made with potassium), and sodium oxide, and there are others as well.\n",
      "################\n"
     ]
    }
   ],
   "source": [
    "queries = [\"How did anne frank die?\",\n",
    "          \"How are glaciers formed?\",\n",
    "          \"How are glacier caves formed?\",\n",
    "          \"What is a desktop computer and where is it typically placed?\",\n",
    "          \"When did the Western Allies invade mainland Italy during World War II?\",\n",
    "          \"What elements make up the Earth's core (approximately) ?\"]\n",
    "\n",
    "results = [ run_pipeline(query) for query in queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b7f52-e5ee-4b47-a682-2796a990d8e6",
   "metadata": {},
   "source": [
    "## Some Limitations and Future improvement scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d4d86b-eb4a-4830-84d6-70bebf3a4b42",
   "metadata": {},
   "source": [
    "### Query Reformulation and Dataset generation\n",
    "#### 1. We can rewrite the users queries and further decompose them to find answers that could be present \n",
    "####    across multiple passages and articles.\n",
    "#### 2. We can generate a synthetic dataset that requires the model to perform multi hop reasoning\n",
    "#### 3. We can generate a much larger dataset.\n",
    "#### 4. There could be other interesting ways of chunking the wikipedia articles, instead of just using passages. \n",
    "####    We can keep an overlap between multiple passages to further enhance context. \n",
    "\n",
    "### RAG pipeline\n",
    "#### 1. We can introduce an augment step where we can generate a set of questions that need to be answered first\n",
    "####    in order to find the answer to the original question\n",
    "#### 2. Instead of showing the complete paragraph as the evidence, we can show the exact part of the paragraph which \n",
    "####    contains the answer \n",
    "#### 3. In the reader stage, instead of sending in 10 passages from k different articles, we can send all passages \n",
    "####    of these k different articles to provide a better context to the LLM\n",
    "#### 4. We could find the embeddings of the entire wikipedia article and store them in our vector store. We then \n",
    "####    use a 2-step process to first narrow down on the correct article and then narrow down on the right passage \n",
    "####    in that article.\n",
    "\n",
    "### Modelling\n",
    "#### 1. Experiments with other Embedding models, loss functions, exhaustive hyper-parameter search\n",
    "#### 2. Benchmarking using other commercial embedders. Ex - OpenAI just released their new v3 embedding model\n",
    "#### 3. We can parse the wikipedia articles, extract their headings and use the section hierarchy to enhance the \n",
    "####    context of the passages.\n",
    "#### 4. Instead of using the encoder based models for generating sentence embeddings, we can use an LLM(a decoder only)\n",
    "####    to generate embeddings. There is a e5-mistral-7b-instruct model which was trained in this manner and is sitting\n",
    "####    top of the embedding benchmarks\n",
    "#### 5. We can use instruction fine tune a smaller LLM like phi-2 to perform the reader task instead of using GPT-4 there. \n",
    "\n",
    "### This field is evolving at such a rapid pace that, we are bombarded with new ideas and content every other day. \n",
    "### So lets keep our heads down, learn from the community and keep growing. Thank you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bce700-b5aa-4b1e-89c8-3116e1053908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
